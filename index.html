<!DOCTYPE html>
<html>

<head>

  <title>M<sup>2</sup>StyleGS: Multi-Modality 3D Style Transfer with Gaussian Splatting</title>
  <link href="https://fonts.googleapis.com/css?family=Noto Serif" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <!-- <link rel="stylesheet" href="./static/css/bulma-slider.min.css"> -->
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <!-- <script src="./static/js/bulma-slider.min.js"></script> -->
  <script src="./static/js/index.js"></script>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title">M<sup>2</sup>StyleGS: Multi-Modality 3D Style Transfer with Gaussian Splatting
            </h1>
            <h2 class="title publication-title is-3"> BMVC 2025 </h2>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://github.com/xingy038" target="_blank">Xingyu Miao</a><sup>1</sup>,</span>
              </span>
              <span class="author-block">
                <a href="https://github.com/Nora202" target="_blank">Xueqi Qiu</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://haorand.github.io/" target="_blank">Haoran Duan</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=lslB5jkAAAAJ&hl=zh-CN" target="_blank">Xian Wu</a><sup>3</sup>,  
              </span><br>
              
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=AVemHcIAAAAJ&hl=en" target="_blank">Jingjing Deng</a><sup>4</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?hl=en&user=IrkuknEAAAAJ" target="_blank">Yang Long</a><sup>1</sup>,
              </span>
              
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Durham university, UK &nbsp; </span>
              <span class="author-block"><sup>2</sup>Newcastle university, UK &nbsp; </span>
              <span class="author-block"><sup>3</sup>Tencent Jarvis Lab, Shenzhen, China</span>
              <span class="author-block"><sup>3</sup>University of Bristol, China</span>
            </div>

            <div class="column has-text-centered">
                <!-- Arxiv Link. -->
                <span class="link-block">
                  <a href="https://bmva-archive.org.uk/bmvc/2025/assets/papers/Paper_133/paper.pdf" class="external-link button is-normal is-rounded is-dark"
                    target="_blank">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/Nora202/MMStyleGS" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code(coming soon)</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body has-text-justified">
        <br>
        <img src="./assets/main2_00.png" width="100%" />
        <h2 class="subtitle">
          Multi-Modality 3D style transfer with reference image or reference text. Utilizing a set of 3D scene images captured from multiple perspectives, the M<sup>2</sup>StyleGS model can effectively apply reference styles described in arbitrary text or derived from any image, achieving high-precision style transformation.
        </h2>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Current 3D style transfer methods usually depend on a reference image to incorporate style into 3D content. However, in many practical applications, users also look forward to transferring styles through textual imagery, instead of being limited to a fixed reference image. To address this limitation, we introduce a novel real-time styling technique M<sup>2</sup>StyleGS. It utilizes the multimodal knowledge refined by CLIP to generate a sequence of precisely color-mapped novel views to achieve instant 3D style transfer with 3D Gaussian Splatting as a backbone.  M<sup>2</sup>StyleGS resolves the abnormal transformation by employing a precise feature alignment process termed "subdivisive flow", which accurately projects the style domain of the mapped CLIP feature to the style domain of the VGG feature. Additionally, we introduce auxiliary observation loss and suppression loss to enhance visual effects. By integrating these technologies, M<sup>2</sup>StyleGS can use text or images as style references to generate a series of style-enhanced novel views. Our experimental results indicate that M<sup>2</sup>StyleGS surpasses our baseline ConRF by up to 25% in terms of consistency and visual quality, measured by RMSE and LPIPS.
            </p>
          </div>
        </div>
      </div>
  </section>
  
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <h2 class="title is-3"><center>Image reference transfer</center></h2>
      <div class="hero-body">
        <div class="columns is-1 is-multiline is-mobile">
          <div class="column is-full">
            <img src="./assets/style_1.png" alt="Sample Image" style="width:100%; height:auto;">
          </div>
        </div>
      </div>
    </div>
  </section>
  
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <h2 class="title is-3"><center>Texture reference transfer</center></h2>
      <div class="hero-body">
        <div class="columns is-1 is-multiline is-mobile">
          <div class="column is-full">
            <img src="./assets/style_2.png" alt="Sample Image" style="width:100%; height:auto;">
          </div>
        </div>
      </div>
    </div>
  </section>

  
</body>
</html>
